{{- if .Values.bootstrap.enabled }}
apiVersion: batch/v1
kind: Job
metadata:
  name: vault-bootstrap
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: vault-bootstrap
    app.kubernetes.io/instance: {{ .Release.Name }}
  annotations:
    # Run after Vault is deployed
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
spec:
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        app.kubernetes.io/name: vault-bootstrap
    spec:
      serviceAccountName: {{ .Release.Name }}
      restartPolicy: OnFailure
      containers:
        - name: bootstrap
          image: hashicorp/vault:1.18
          env:
            - name: VAULT_ADDR
              value: "http://{{ .Release.Name }}.{{ .Release.Namespace }}.svc:{{ .Values.ports.vault.http }}"
          command: ["/bin/sh", "-c"]
          args:
            - |
              set -e

              echo "=== Vault Bootstrap Script ==="

              # Install kubectl (not included in vault image)
              echo "Installing kubectl..."
              wget -q -O /tmp/kubectl "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
              chmod +x /tmp/kubectl
              mv /tmp/kubectl /usr/local/bin/kubectl
              echo "kubectl installed"

              # Wait for Vault to be responding (even if sealed/uninitialized)
              # Exit codes: 0=unsealed, 1=error, 2=sealed (includes uninitialized)
              echo "Waiting for Vault to be available..."
              MAX_RETRIES=60
              RETRY_COUNT=0
              while true; do
                set +e  # Temporarily disable exit on error for status check
                vault status >/dev/null 2>&1
                rc=$?
                set -e
                if [ $rc -eq 0 ] || [ $rc -eq 2 ]; then
                  echo "Vault is responding (exit code $rc)"
                  break
                fi
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
                  echo "ERROR: Vault did not become available after $MAX_RETRIES attempts"
                  exit 1
                fi
                echo "Vault not ready (exit code $rc), waiting... (attempt $RETRY_COUNT/$MAX_RETRIES)"
                sleep 2
              done

              # Check if Vault is initialized
              if vault status | grep -q "Initialized.*false"; then
                echo "Initializing Vault..."
                # With Transit auto-unseal, use recovery shares instead of key shares
                vault operator init -recovery-shares=1 -recovery-threshold=1 -format=json > /tmp/init.json
                cat /tmp/init.json

                # Extract root token using sed (more reliable than grep for JSON)
                ROOT_TOKEN=$(sed -n 's/.*"root_token": *"\([^"]*\)".*/\1/p' /tmp/init.json)
                echo "Extracted root token: ${ROOT_TOKEN:0:10}..."

                # Store root token in Kubernetes secret
                cat <<EOSECRET | kubectl apply -f -
              apiVersion: v1
              kind: Secret
              metadata:
                name: vault-root-token
                namespace: {{ .Release.Namespace }}
              type: Opaque
              stringData:
                token: "${ROOT_TOKEN}"
              EOSECRET

                echo "Vault initialized and root token stored"
              else
                echo "Vault already initialized"
                # Get root token from secret
                ROOT_TOKEN=$(kubectl get secret vault-root-token -n {{ .Release.Namespace }} -o jsonpath='{.data.token}' | base64 -d)
              fi

              # Wait for Vault to be unsealed (auto-unseal should handle this)
              echo "Waiting for Vault to be unsealed..."
              until vault status 2>/dev/null | grep -q "Sealed.*false"; do
                echo "Vault still sealed, waiting..."
                sleep 2
              done

              echo "Vault is unsealed, proceeding with configuration..."

              # Login with root token
              vault login "$ROOT_TOKEN"

              # Enable KV-v2 secrets engine
              echo "Enabling KV-v2 secrets engine..."
              vault secrets enable -path=secret kv-v2 2>/dev/null || echo "KV-v2 already enabled"

              # Apply policies
              echo "Applying policies..."
              vault policy write monitoring /config/policy-monitoring.hcl
              vault policy write argocd /config/policy-argocd.hcl

              # Configure Kubernetes auth
              echo "Configuring Kubernetes auth..."
              vault auth enable kubernetes 2>/dev/null || echo "Kubernetes auth already enabled"
              vault write auth/kubernetes/config \
                kubernetes_host="https://kubernetes.default.svc:443"

              # Create vault-secrets-operator role
              echo "Creating Kubernetes auth roles..."
              vault write auth/kubernetes/role/vault-secrets-operator \
                bound_service_account_names="vault-secrets-operator-controller-manager,default" \
                bound_service_account_namespaces="vault-secrets-operator,monitoring,argocd" \
                policies="monitoring,argocd" \
                ttl=24h

              # Seed secrets from the pre-created Secret (created by setup.sh)
              echo "Seeding secrets from vault-bootstrap-secrets..."

              # Read secrets from mounted Secret
              GRAFANA_USER=$(cat /secrets/grafana-user)
              GRAFANA_PASSWORD=$(cat /secrets/grafana-password)
              ARGOCD_PASSWORD_HASH=$(cat /secrets/argocd-password-hash)
              ARGOCD_SECRET_KEY=$(cat /secrets/argocd-server-secret-key)
              PAGERDUTY_ROUTING_KEY=$(cat /secrets/pagerduty-routing-key)
              SLACK_CRITICAL_WEBHOOK=$(cat /secrets/slack-critical-webhook)
              SLACK_WARNING_WEBHOOK=$(cat /secrets/slack-warning-webhook)

              # Seed Grafana secrets
              vault kv put secret/monitoring/grafana \
                admin-user="$GRAFANA_USER" \
                admin-password="$GRAFANA_PASSWORD"

              # Seed Alertmanager secrets
              vault kv put secret/monitoring/alertmanager \
                slack-critical-webhook="$SLACK_CRITICAL_WEBHOOK" \
                slack-warning-webhook="$SLACK_WARNING_WEBHOOK" \
                pagerduty-routing-key="$PAGERDUTY_ROUTING_KEY"

              # Seed ArgoCD secrets
              vault kv put secret/argocd/admin \
                "admin.password=$ARGOCD_PASSWORD_HASH" \
                "admin.passwordMtime=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
                "server.secretkey=$ARGOCD_SECRET_KEY"

              echo "=== Vault Bootstrap Complete ==="
          volumeMounts:
            - name: config
              mountPath: /config
              readOnly: true
            - name: secrets
              mountPath: /secrets
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: vault-bootstrap-config
        - name: secrets
          secret:
            secretName: vault-bootstrap-secrets
---
# RBAC for bootstrap job to create secrets
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: vault-bootstrap
  namespace: {{ .Release.Namespace }}
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "create", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: vault-bootstrap
  namespace: {{ .Release.Namespace }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: vault-bootstrap
subjects:
  - kind: ServiceAccount
    name: {{ .Release.Name }}
    namespace: {{ .Release.Namespace }}
---
# Network policy for bootstrap job
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: vault-bootstrap
  namespace: {{ .Release.Namespace }}
spec:
  endpointSelector:
    matchLabels:
      app.kubernetes.io/name: vault-bootstrap

  egress:
    # Allow DNS resolution
    - toEndpoints:
        - matchLabels:
            k8s:io.kubernetes.pod.namespace: kube-system
            k8s-app: kube-dns
      toPorts:
        - ports:
            - port: "{{ .Values.ports.dns }}"
              protocol: UDP

    # Allow Kubernetes API access (for kubectl commands)
    - toEntities:
        - kube-apiserver

    # Allow connection to Vault server
    - toEndpoints:
        - matchLabels:
            app.kubernetes.io/name: vault
            component: server
      toPorts:
        - ports:
            - port: "{{ .Values.ports.vault.http }}"
              protocol: TCP

    # Allow downloading kubectl from the internet
    - toEntities:
        - world
      toPorts:
        - ports:
            - port: "443"
              protocol: TCP
            - port: "80"
              protocol: TCP
{{- end }}
