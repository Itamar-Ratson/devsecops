# Gateway configuration
gateway:
  name: main-gateway
  namespace: gateway

# Headlamp configuration
headlamp:
  replicaCount: 1

  # v0.28.0 is the last version with working OIDC refresh tokens
  # See: https://github.com/kubernetes-sigs/headlamp/issues/3143
  image:
    registry: ghcr.io
    repository: headlamp-k8s/headlamp
    tag: "v0.28.0"

  config:
    oidc:
      # Do not create secret from values - we use external secret from VSO
      secret:
        create: false
      # Client secret from VaultStaticSecret
      externalSecret:
        enabled: true
        name: headlamp-oidc-secret
    # Note: -oidc-ca-file not available in v0.28.0
    # -insecure-ssl needed because client-go doesn't respect SSL_CERT_FILE
    # and uses ServiceAccount CA which doesn't include kube-oidc-proxy's CA
    extraArgs:
      - -insecure-ssl

  # Cluster discovery from ArgoCD secrets
  # Headlamp reads secrets with label: argocd.argoproj.io/secret-type=cluster
  clusterRoleBinding:
    create: true
    clusterRoleName: cluster-admin

  service:
    type: ClusterIP
    port: 80

  # Disable built-in ingress (we use HTTPRoute)
  ingress:
    enabled: false

  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

  # Mount CA bundle from trust-manager for OIDC TLS verification
  volumes:
    - name: ca-bundle
      configMap:
        name: gateway-ca-bundle
        optional: true  # Don't fail if trust-manager hasn't synced yet

  volumeMounts:
    - name: ca-bundle
      mountPath: /etc/headlamp/certs/ca.crt
      subPath: ca.crt
      readOnly: true

  # Point Go's TLS to use our CA bundle
  env:
    - name: SSL_CERT_FILE
      value: /etc/headlamp/certs/ca.crt
    # Point Headlamp to kube-oidc-proxy instead of real API server
    # This allows OIDC token validation through the proxy
    - name: KUBERNETES_SERVICE_HOST
      value: kube-oidc-proxy.kube-oidc-proxy.svc
    - name: KUBERNETES_SERVICE_PORT
      value: "443"

  # Run as non-root
  securityContext:
    runAsNonRoot: true
    runAsUser: 100
    runAsGroup: 101

  podSecurityContext:
    fsGroup: 101
